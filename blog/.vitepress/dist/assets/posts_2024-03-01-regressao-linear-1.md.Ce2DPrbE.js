import{_ as l,c as n,a2 as t,G as i,w as r,j as o,B as d,o as p,a as s}from"./chunks/framework.CDI8fxxe.js";const q=JSON.parse('{"title":"Regressão Linear Primeiro Contato","description":"","frontmatter":{"title":"Regressão Linear Primeiro Contato","tags":["regressão linear","aprendizagem de máquina"],"editLink":true,"aside":true,"sidebar":false,"layout":"doc"},"headers":[],"relativePath":"posts/2024-03-01-regressao-linear-1.md","filePath":"posts/2024-03-01-regressao-linear-1.md"}'),c={name:"posts/2024-03-01-regressao-linear-1.md"};function m(u,e,g,v,f,x){const a=d("center");return p(),n("div",null,[e[2]||(e[2]=t('<h1 id="regressao-linear-1" tabindex="-1">Regressão Linear (1#) <a class="header-anchor" href="#regressao-linear-1" aria-label="Permalink to &quot;Regressão Linear (1#)&quot;">​</a></h1><p><em>01/03/2024</em></p><p><em>Por Giseldo Neo</em></p><h2 id="introducao" tabindex="-1">Introdução <a class="header-anchor" href="#introducao" aria-label="Permalink to &quot;Introdução&quot;">​</a></h2><p>A Regressão linear é um método estatístico utilizado para avaliar a relação causal e quantitativa entre duas variáveis, chamada de variável dependente e variável independente, respectivamente. O modelo de regressão linear tem a seguinte forma: y = a + bx + e, onde y é a variável dependente, x é a variável independente, a é o intercepto, b é a reta inclinada e e é o erro. Com a regressão podemos encontrar um modelo matemático que melhor descreva a relação entre as variáveis (x) e (y).</p><h3 id="caracteristicas" tabindex="-1">Características <a class="header-anchor" href="#caracteristicas" aria-label="Permalink to &quot;Características&quot;">​</a></h3><ol><li>Relação linear: A relação entre as variáveis é modelada como uma equação linear.</li><li>Variável dependente: y (ou resposta)</li><li>Variável(s) independente(s): x (ou preditor(es))</li><li>Coeficientes: Parâmetros que descrevem a relação entre x e y</li></ol><p><strong>Tipos</strong></p><ol><li>Regressão linear simples: Uma variável independente.</li><li>Regressão linear múltipla: Mais de uma variável independente.</li></ol><p>Equação da regressão linear:</p><p>y = β0 + β1x + ε</p><p>Onde:</p><ul><li>y: Variável dependente</li><li>x: Variável independente</li><li>β0: Intercepto (ou constante)</li><li>β1: Coeficiente de regressão</li><li>ε: Erro residual (ou ruído)</li></ul><p><strong>Objetivos</strong></p><ol><li>Previsão: Prever valores de y com base em x.</li><li>Análise da relação: Entender como x afeta y.</li><li>Identificação de padrões: Detectar tendências e padrões nos dados.</li></ol><p><strong>Pressupostos</strong></p><ol><li>Linearidade: Relação linear entre x e y.</li><li>Independência: Observações independentes.</li><li>Homocedasticidade: Variância constante dos resíduos.</li><li>Normalidade: Distribuição normal dos resíduos.</li><li>Não multicolinearidade: Variáveis independentes não correlacionadas.</li></ol><p><strong>Métricas de avaliação</strong></p><ol><li>Coeficiente de determinação (R²)</li><li>Erro quadrático médio (MSE)</li><li>Raiz do erro quadrático médio (RMSE)</li></ol><p><strong>Aplicações</strong></p><ol><li>Análise de dados</li><li>Previsão de vendas</li><li>Modelagem financeira</li><li>Análise de marketing</li><li>Pesquisa científica</li></ol><p><strong>Limitações da regressão linear</strong></p><ol><li>Suposições rígidas</li><li>Sensibilidade a outliers</li><li>Não captura relações não lineares</li><li>Não considera interações entre variáveis</li></ol><p><strong>Técnicas relacionadas</strong></p><ol><li>Regressão polinomial</li><li>Regressão logística</li></ol>',25)),i(a,null,{default:r(()=>e[0]||(e[0]=[s(". . .")])),_:1}),o("p",null,[o("em",null,[i(a,null,{default:r(()=>e[1]||(e[1]=[s("Até o próximo artigo")])),_:1})])])])}const R=l(c,[["render",m]]);export{q as __pageData,R as default};
