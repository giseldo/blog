<!DOCTYPE html>
<html lang="br" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Nemotron LLM 70B - Um primeiro contato | Neo Blog</title>
    <meta name="description" content="Notícias relacionadas a tecnologia e IA">
    <meta name="generator" content="VitePress v1.5.0">
    <link rel="preload stylesheet" href="/blog/assets/style.xUmBJNa8.css" as="style">
    <link rel="preload stylesheet" href="/blog/vp-icons.css" as="style">
    
    <script type="module" src="/blog/assets/app.Uiq2ixZ5.js"></script>
    <link rel="preload" href="/blog/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/blog/assets/chunks/framework.CDI8fxxe.js">
    <link rel="modulepreload" href="/blog/assets/chunks/theme.CNCmLfxL.js">
    <link rel="modulepreload" href="/blog/assets/chunks/katex.CNfcEN01.js">
    <link rel="modulepreload" href="/blog/assets/chunks/dagre-4EVJKHTY.Dr-c5Ijz.js">
    <link rel="modulepreload" href="/blog/assets/chunks/c4Diagram-6F5ED5ID.Y42I-62Z.js">
    <link rel="modulepreload" href="/blog/assets/chunks/flowDiagram-7ASYPVHJ.BUtAGuh-.js">
    <link rel="modulepreload" href="/blog/assets/chunks/erDiagram-6RL3IURR.Bfor7t1h.js">
    <link rel="modulepreload" href="/blog/assets/chunks/gitGraphDiagram-NRZ2UAAF.BaO2rZO_.js">
    <link rel="modulepreload" href="/blog/assets/chunks/ganttDiagram-NTVNEXSI.Awe4FVgp.js">
    <link rel="modulepreload" href="/blog/assets/chunks/infoDiagram-A4XQUW5V.D7e76ncI.js">
    <link rel="modulepreload" href="/blog/assets/chunks/pieDiagram-YF2LJOPJ.CIVdwKKG.js">
    <link rel="modulepreload" href="/blog/assets/chunks/quadrantDiagram-OS5C2QUG.BdqT7mve.js">
    <link rel="modulepreload" href="/blog/assets/chunks/xychartDiagram-6QU3TZC5.DYBgFUEZ.js">
    <link rel="modulepreload" href="/blog/assets/chunks/requirementDiagram-MIRIMTAZ.DZbWdxpX.js">
    <link rel="modulepreload" href="/blog/assets/chunks/sequenceDiagram-G6AWOVSC.gdu3LJTC.js">
    <link rel="modulepreload" href="/blog/assets/chunks/classDiagram-LNE6IOMH.9YXhxEel.js">
    <link rel="modulepreload" href="/blog/assets/chunks/classDiagram-v2-MQ7JQ4JX.9YXhxEel.js">
    <link rel="modulepreload" href="/blog/assets/chunks/stateDiagram-MAYHULR4.B-r_o91g.js">
    <link rel="modulepreload" href="/blog/assets/chunks/stateDiagram-v2-4JROLMXI.DVqyGGs4.js">
    <link rel="modulepreload" href="/blog/assets/chunks/journeyDiagram-G5WM74LC.Bl9uAoXf.js">
    <link rel="modulepreload" href="/blog/assets/chunks/timeline-definition-U7ZMHBDA.D6aEmUf_.js">
    <link rel="modulepreload" href="/blog/assets/chunks/mindmap-definition-GWI6TPTV.CR-mXYao.js">
    <link rel="modulepreload" href="/blog/assets/chunks/kanban-definition-QRCXZQQD.B6FMTnAR.js">
    <link rel="modulepreload" href="/blog/assets/chunks/sankeyDiagram-Y46BX6SQ.Cfxk0x7U.js">
    <link rel="modulepreload" href="/blog/assets/chunks/diagram-QW4FP2JN.CxHusuSN.js">
    <link rel="modulepreload" href="/blog/assets/chunks/blockDiagram-ZHA2E4KO.C1VnHI7o.js">
    <link rel="modulepreload" href="/blog/assets/chunks/architectureDiagram-UYN6MBPD.1QVXJ2-A.js">
    <link rel="modulepreload" href="/blog/assets/chunks/virtual_mermaid-config.DDnGl6nM.js">
    <link rel="modulepreload" href="/blog/assets/posts_2024-05-01-llm-nemotron.md.C9YLQ5dZ.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-d8d3e66f><!--[--><!--]--><!--[--><span tabindex="-1" data-v-b20e631d></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-b20e631d> Skip to content </a><!--]--><!----><header class="VPNav" data-v-d8d3e66f data-v-64278d09><div class="VPNavBar" data-v-64278d09 data-v-2f9a91a8><div class="wrapper" data-v-2f9a91a8><div class="container" data-v-2f9a91a8><div class="title" data-v-2f9a91a8><div class="VPNavBarTitle" data-v-2f9a91a8 data-v-db1abf29><a class="title" href="/blog/" data-v-db1abf29><!--[--><!--]--><!----><span data-v-db1abf29>Neo Blog</span><!--[--><!--]--></a></div></div><div class="content" data-v-2f9a91a8><div class="content-body" data-v-2f9a91a8><!--[--><!--]--><div class="VPNavBarSearch search" data-v-2f9a91a8><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-2f9a91a8 data-v-94e0de4d><span id="main-nav-aria-label" class="visually-hidden" data-v-94e0de4d> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/" tabindex="0" data-v-94e0de4d data-v-b04b12fe><!--[--><span data-v-b04b12fe>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/pages/sobre.html" tabindex="0" data-v-94e0de4d data-v-b04b12fe><!--[--><span data-v-b04b12fe>Sobre</span><!--]--></a><!--]--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="http://giseldo.github.io/cursos" target="_blank" rel="noreferrer" tabindex="0" data-v-94e0de4d data-v-b04b12fe><!--[--><span data-v-b04b12fe>Cursos</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-2f9a91a8 data-v-e6826308><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-e6826308 data-v-77e720fe data-v-b5a0f3c5><span class="check" data-v-b5a0f3c5><span class="icon" data-v-b5a0f3c5><!--[--><span class="vpi-sun sun" data-v-77e720fe></span><span class="vpi-moon moon" data-v-77e720fe></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-2f9a91a8 data-v-cb473b7f data-v-e0cde419><!--[--><a class="VPSocialLink no-icon" href="https://github.com/giseldo/blog" aria-label="github" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-2f9a91a8 data-v-c4883afd data-v-3980e32a><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-3980e32a><span class="vpi-more-horizontal icon" data-v-3980e32a></span></button><div class="menu" data-v-3980e32a><div class="VPMenu" data-v-3980e32a data-v-f8f1a359><!----><!--[--><!--[--><!----><div class="group" data-v-c4883afd><div class="item appearance" data-v-c4883afd><p class="label" data-v-c4883afd>Appearance</p><div class="appearance-action" data-v-c4883afd><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-c4883afd data-v-77e720fe data-v-b5a0f3c5><span class="check" data-v-b5a0f3c5><span class="icon" data-v-b5a0f3c5><!--[--><span class="vpi-sun sun" data-v-77e720fe></span><span class="vpi-moon moon" data-v-77e720fe></span><!--]--></span></span></button></div></div></div><div class="group" data-v-c4883afd><div class="item social-links" data-v-c4883afd><div class="VPSocialLinks social-links-list" data-v-c4883afd data-v-e0cde419><!--[--><a class="VPSocialLink no-icon" href="https://github.com/giseldo/blog" aria-label="github" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-2f9a91a8 data-v-6c970607><span class="container" data-v-6c970607><span class="top" data-v-6c970607></span><span class="middle" data-v-6c970607></span><span class="bottom" data-v-6c970607></span></span></button></div></div></div></div><div class="divider" data-v-2f9a91a8><div class="divider-line" data-v-2f9a91a8></div></div></div><!----></header><div class="VPLocalNav empty fixed" data-v-d8d3e66f data-v-f3371c70><div class="container" data-v-f3371c70><!----><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-f3371c70 data-v-7bf35b01><button data-v-7bf35b01>Return to top</button><!----></div></div></div><!----><div class="VPContent" id="VPContent" data-v-d8d3e66f data-v-6a411d75><div class="VPDoc has-aside" data-v-6a411d75 data-v-5e576dee><!--[--><!--]--><div class="container" data-v-5e576dee><div class="aside" data-v-5e576dee><div class="aside-curtain" data-v-5e576dee></div><div class="aside-container" data-v-5e576dee><div class="aside-content" data-v-5e576dee><div class="VPDocAside" data-v-5e576dee data-v-8e8afcfb><!--[--><!--]--><!--[--><!--[--><!--[--><!--[--> My custom sidebar top content <!--]--><!--]--><!--]--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-8e8afcfb data-v-f2249f6d><div class="content" data-v-f2249f6d><div class="outline-marker" data-v-f2249f6d></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f2249f6d>On this page</div><ul class="VPDocOutlineItem root" data-v-f2249f6d data-v-e7c3772a><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-8e8afcfb></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5e576dee><div class="content-container" data-v-5e576dee><!--[--><!--]--><main class="main" data-v-5e576dee><div style="position:relative;" class="vp-doc _blog_posts_2024-05-01-llm-nemotron" data-v-5e576dee><div><h1 id="nemotron-llm-70b-um-primeiro-contato" tabindex="-1">Nemotron LLM 70B - Um primeiro contato <a class="header-anchor" href="#nemotron-llm-70b-um-primeiro-contato" aria-label="Permalink to &quot;Nemotron LLM 70B - Um primeiro contato&quot;">​</a></h1><p><em>01/03/2024</em></p><p><em>Por Giseldo Neo</em></p><p>Em julho de 2024, a Meta lançou um modelo de linguagem (LLM) open-source, o <em>Llama-3.1-70B</em>. Um pouco depois, em setembro a empresa NVIDIA lançou um derivado deste, o <em>Llama 3.1-Nemotron-51B-Instruct</em>. E em outubro lançou finalmente um modelo de 70b, o <em>Llama 3.1 nemotron-70b-instruct</em>.</p><p>O <em>nemotron-70b</em> performou melhor, em alguns testes comparativos, do que o GPT-4o. Nos testes, ele liderou em desempenho geral e também se destacou nas categorias chat (<em>chat score</em>) e raciocínio (<em>reasoning score</em>). Veja na <strong>Tabela 1</strong> os dados comparativos com mais detalhes.</p><!----><table tabindex="0"><thead><tr><th>Model</th><th style="text-align:right;">Overall Score</th><th style="text-align:right;">Chat Score</th><th style="text-align:right;">Reasoning Score</th></tr></thead><tbody><tr><td>Llama 3.1 Nemotron-70B</td><td style="text-align:right;">94.1</td><td style="text-align:right;">97.5</td><td style="text-align:right;">98.1</td></tr><tr><td>Skywork-Reward-Gemma-2-27B</td><td style="text-align:right;">93.8</td><td style="text-align:right;">95.8</td><td style="text-align:right;">96.1</td></tr><tr><td>TextEval-Llama3.1-70B</td><td style="text-align:right;">93.5</td><td style="text-align:right;">94.1</td><td style="text-align:right;">96.4</td></tr><tr><td>GPT-4o</td><td style="text-align:right;">86.7</td><td style="text-align:right;">96.1</td><td style="text-align:right;">86.6</td></tr></tbody></table><!----><h2 id="testes-de-uso" tabindex="-1">Testes de uso <a class="header-anchor" href="#testes-de-uso" aria-label="Permalink to &quot;Testes de uso&quot;">​</a></h2><p>O Nemontron pode ser testado em <a href="https://build.nvidia.com" target="_blank" rel="noreferrer">build.nvidia.com</a>, especificamente <a href="https://build.nvidia.com/nvidia/llama-3_1-nemotron-70b-instruct?snippet_tab=Node" target="_blank" rel="noreferrer">neste link</a>. A inscrição concede acesso a 100.000 chamadas de API gratuitas. Além disso, ele está disponível para baixar no <a href="https://huggingface.co/nvidia/Llama-3_1-Nemotron-51B-Instruct" target="_blank" rel="noreferrer">Hugging Face</a>. Porém, haja poder de processamento para uma consulta local a este modelo em uma PC de mesa.</p><p>Realizei algumas consultas no site da NVIDIA (<strong>Figura 1</strong>) e a velocidade da resposta deixou muito a desejar em relação a quantidade de tokens por minuto. Um versão do <a href="https://console.groq.com/playground" target="_blank" rel="noreferrer">Groq</a> disponível no Groq Cloud (<em>Figura 2</em>), que usa uma versão também customizada do Llama, o <em>llama3-groq-70b-8192-tool-use-preview</em>, é muito mais veloz do que a disponibilizada no site da NVIDIA. Provavelmente isto está relacionado mais ao hardware da Groq, que parece ser mais eficiente, independente do modelo. Cabe ressaltar que a versão da NVIDIA deu uma resposta bem mais completa que a versão do Groq, para o mesmo prompt.</p><p><strong>Figura 1</strong> - Demonstração do Nemotron 70B no site da NVidia</p><p>Fonte: O Autor (2024)</p><p><strong>Figura 2</strong> - Demonstração no Groq Cloud do modelo 70B tool use preview</p><p>Fonte: O Autor (2024)</p><h2 id="arquitetura" tabindex="-1">Arquitetura <a class="header-anchor" href="#arquitetura" aria-label="Permalink to &quot;Arquitetura&quot;">​</a></h2><p>Um LLM geralmente utiliza a arquitetura <em>transformer</em>, e no Nemotron não foi diferente. Esta arquitetura já é conhecida e permite que o modelo capture dependências de longo alcance no texto, tornando-o apto a compreender o contexto e a gerar respostas.</p><p>Outro recurso utilizado é o <em>Attention Multi-Head</em> que permite que o modelo se concentre em diferentes partes da entrada simultaneamente, aprimorando sua capacidade de compreender consultas complexas e produzir resultados diferenciados.</p><p>Por fim, foi implementado no modelo, a <em>normalização de camadas</em>. Ela ajuda a estabilizar o treinamento e a melhorar as taxas de convergência, resultando em um aprendizado mais rápido e eficiente. o modelo foi treinado em uma ampla gama de dados licenciados com a licença (CC-BY-4.0), que inclui livros, artigos e conteúdo da web. Ressaltando que o BY da licença exige que o crédito seja dado ao autor.</p><p>De acordo com a NVIDIA, o processo de treinamento do <em>Llama 3.1 Nemotron-70B</em> incluiu:</p><ul><li>aprendizagem supervisionada</li><li>aprendizagem por reforço de feedback humano.</li><li>Modelagem de recompensa: O modelo prevê a qualidade da resposta com base nas interações do usuário. Este mecanismo permite ajustar seus resultados de forma dinâmica, melhorando ao longo do tempo com base no feedback do mundo real.</li></ul><h2 id="codigo" tabindex="-1">Código <a class="header-anchor" href="#codigo" aria-label="Permalink to &quot;Código&quot;">​</a></h2><p>Em relação a código, a consulta ao modelo em python utiliza a mesma API do LLM da OpenAI (conforme pode ser visto no código abaixo), alterando somente a <em>base url</em>.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">client </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  base_url</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;https://integrate.api.nvidia.com/v1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  api_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">completion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> client.chat.completions.create(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;nvidia/llama-3.1-nemotron-70b-instruct&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  messages</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;What is machine learning?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  temperature</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  top_p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  max_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1024</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  stream</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> chunk </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> completion:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> chunk.choices[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].delta.content </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(chunk.choices[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].delta.content, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">end</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Curtiu? Deixei um comentário. Até o próximo post.</p><h3 id="referencias" tabindex="-1">Referências <a class="header-anchor" href="#referencias" aria-label="Permalink to &quot;Referências&quot;">​</a></h3><ul><li><a href="https://blog.getbind.co/2024/10/17/llama-3-1-nemotron-70b-is-it-better-for-coding-compared-to-gpt-4o-and-claude-3-5-sonnet/" target="_blank" rel="noreferrer">Bind AI Blog post</a></li><li><a href="https://creativecommons.org/share-your-work/cclicenses/" target="_blank" rel="noreferrer">CC-BY</a></li><li><a href="https://console.groq.com/" target="_blank" rel="noreferrer">GROQ</a></li><li><a href="https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b" target="_blank" rel="noreferrer">NVIDIA Blog post</a></li><li><a href="https://www.reddit.com/r/LocalLLaMA/comments/1fnp2kt/new_llama31nemotron51b_instruct_model_from_nvidia/" target="_blank" rel="noreferrer">Reddit post</a></li></ul><!----><p><em><!----></em></p></div></div></main><footer class="VPDocFooter" data-v-5e576dee data-v-7ae10264><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-7ae10264><span class="visually-hidden" id="doc-footer-aria-label" data-v-7ae10264>Pager</span><div class="pager" data-v-7ae10264><a class="VPLink link pager-link prev" href="/blog/posts/2024-11-19-codegpt.html" data-v-7ae10264><!--[--><span class="desc" data-v-7ae10264>Previous page</span><span class="title" data-v-7ae10264>CodeGPT</span><!--]--></a></div><div class="pager" data-v-7ae10264><a class="VPLink link pager-link next" href="/blog/posts/2024-04-01-redes-neurais-1.html" data-v-7ae10264><!--[--><span class="desc" data-v-7ae10264>Next page</span><span class="title" data-v-7ae10264>Redes Neurais (#1)</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter" data-v-d8d3e66f data-v-bc8227f9><div class="container" data-v-bc8227f9><p class="message" data-v-bc8227f9>Lançado sob a Licença MIT.</p><p class="copyright" data-v-bc8227f9>Direitos autorais © 2024 Giseldo Neo</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"index.md\":\"CPOQ7bGT\",\"pages_sobre.md\":\"D0lStW3H\",\"posts_2024-01-01-streamlit.md\":\"CeUGIhxp\",\"posts_2024-02-01-am-1.md\":\"wU64L6TP\",\"posts_2024-02-02-am-2-heuristicas.md\":\"DG7I415c\",\"posts_2024-03-01-regressao-linear-1.md\":\"Ce2DPrbE\",\"posts_2024-04-01-redes-neurais-1.md\":\"BBDXLG4D\",\"posts_2024-05-01-llm-nemotron.md\":\"C9YLQ5dZ\",\"posts_2024-11-19-codegpt.md\":\"D9FE9XnP\",\"posts_2024-11-21-groq-vs-grok.md\":\"BwD5ZxwZ\",\"posts_2024-11-23-ia-noticias.md\":\"4OLBMg17\",\"posts_2024-12-08-avaliacao-por-pares.md\":\"BftfRUZa\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"br\",\"dir\":\"ltr\",\"title\":\"Neo Blog\",\"description\":\"Notícias relacionadas a tecnologia e IA\",\"base\":\"/blog/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Sobre\",\"link\":\"/pages/sobre\"},{\"text\":\"Cursos\",\"link\":\"http://giseldo.github.io/cursos\"}],\"sidebar\":[{\"text\":\"Artigos\",\"items\":[{\"text\":\"Avaliação por pares\",\"link\":\"/posts/2024-12-08-avaliacao-por-pares\"},{\"text\":\"IA notícias\",\"link\":\"/posts/2024-11-23-IA-noticias\"},{\"text\":\"Groq vs Grok\",\"link\":\"/posts/2024-11-21-groq-vs-grok\"},{\"text\":\"CodeGPT\",\"link\":\"/posts/2024-11-19-codegpt\"},{\"text\":\"LLM Nemotron\",\"link\":\"/posts/2024-05-01-llm-nemotron\"},{\"text\":\"Redes Neurais (#1)\",\"link\":\"/posts/2024-04-01-redes-neurais-1\"},{\"text\":\"Regressão linear (#1)\",\"link\":\"/posts/2024-03-01-regressao-linear-1\"},{\"text\":\"Aprendizagem de máquina (#2) - Heurísticas\",\"link\":\"/posts/2024-02-02-am-2-heuristicas\"},{\"text\":\"Aprendizagem de máquina (#1)\",\"link\":\"/posts/2024-02-01-am-1\"},{\"text\":\"Streamlit (#1)\",\"link\":\"/posts/2024-01-01-streamlit\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/giseldo/blog\"}],\"footer\":{\"message\":\"Lançado sob a Licença MIT.\",\"copyright\":\"Direitos autorais © 2024 Giseldo Neo\"},\"search\":{\"provider\":\"local\"},\"mermaid\":{}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>