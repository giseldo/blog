<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>LLM Nemotron 70B | Neo Blog</title>
    <meta name="description" content="Postagem explicando o LLM da Nvidia Nemotron">
    <meta name="generator" content="VitePress v1.5.0">
    <link rel="preload stylesheet" href="/blog/assets/style.cMfZQr_N.css" as="style">
    <link rel="preload stylesheet" href="/blog/vp-icons.css" as="style">
    
    <script type="module" src="/blog/assets/app.MAd84UOp.js"></script>
    <link rel="preload" href="/blog/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/blog/assets/chunks/framework.DgQqy4lg.js">
    <link rel="modulepreload" href="/blog/assets/chunks/theme.BC42PZ3u.js">
    <link rel="modulepreload" href="/blog/assets/chunks/katex.NieGjnhU.js">
    <link rel="modulepreload" href="/blog/assets/chunks/dagre-4EVJKHTY.F_xQSeMs.js">
    <link rel="modulepreload" href="/blog/assets/chunks/c4Diagram-6F5ED5ID.5qnAKHWK.js">
    <link rel="modulepreload" href="/blog/assets/chunks/flowDiagram-7ASYPVHJ.BRThagp7.js">
    <link rel="modulepreload" href="/blog/assets/chunks/erDiagram-6RL3IURR.mEQfQkFD.js">
    <link rel="modulepreload" href="/blog/assets/chunks/gitGraphDiagram-NRZ2UAAF.CvgR7HwR.js">
    <link rel="modulepreload" href="/blog/assets/chunks/ganttDiagram-NTVNEXSI.g3vsj3Gf.js">
    <link rel="modulepreload" href="/blog/assets/chunks/infoDiagram-A4XQUW5V.BCg5m3o2.js">
    <link rel="modulepreload" href="/blog/assets/chunks/pieDiagram-YF2LJOPJ.BD54TN3w.js">
    <link rel="modulepreload" href="/blog/assets/chunks/quadrantDiagram-OS5C2QUG.DqksRaak.js">
    <link rel="modulepreload" href="/blog/assets/chunks/xychartDiagram-6QU3TZC5.C1J4ZNb7.js">
    <link rel="modulepreload" href="/blog/assets/chunks/requirementDiagram-MIRIMTAZ.y6d1qDlZ.js">
    <link rel="modulepreload" href="/blog/assets/chunks/sequenceDiagram-G6AWOVSC.DrdnITwp.js">
    <link rel="modulepreload" href="/blog/assets/chunks/classDiagram-LNE6IOMH.Dfa1te5U.js">
    <link rel="modulepreload" href="/blog/assets/chunks/classDiagram-v2-MQ7JQ4JX.Dfa1te5U.js">
    <link rel="modulepreload" href="/blog/assets/chunks/stateDiagram-MAYHULR4.C8Z8gWla.js">
    <link rel="modulepreload" href="/blog/assets/chunks/stateDiagram-v2-4JROLMXI.DFdKp3jv.js">
    <link rel="modulepreload" href="/blog/assets/chunks/journeyDiagram-G5WM74LC.BeXrYZ0V.js">
    <link rel="modulepreload" href="/blog/assets/chunks/timeline-definition-U7ZMHBDA.DSH6_OIw.js">
    <link rel="modulepreload" href="/blog/assets/chunks/mindmap-definition-GWI6TPTV.CLLuKlrg.js">
    <link rel="modulepreload" href="/blog/assets/chunks/kanban-definition-QRCXZQQD.rJEKTqhF.js">
    <link rel="modulepreload" href="/blog/assets/chunks/sankeyDiagram-Y46BX6SQ.B1RqhXcq.js">
    <link rel="modulepreload" href="/blog/assets/chunks/diagram-QW4FP2JN.D13E4EQG.js">
    <link rel="modulepreload" href="/blog/assets/chunks/blockDiagram-ZHA2E4KO.BOenFPWe.js">
    <link rel="modulepreload" href="/blog/assets/chunks/architectureDiagram-UYN6MBPD.gUFYylAj.js">
    <link rel="modulepreload" href="/blog/assets/chunks/virtual_mermaid-config.DDnGl6nM.js">
    <link rel="modulepreload" href="/blog/assets/posts_2024-05-01-llm-nemotron.md.y6VXXL5R.lean.js">
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-YVNTETJZ36"></script>
    <script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-YVNTETJZ36");</script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-d8d3e66f><!--[--><!--]--><!--[--><span tabindex="-1" data-v-b20e631d></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-b20e631d> Skip to content </a><!--]--><!----><header class="VPNav" data-v-d8d3e66f data-v-64278d09><div class="VPNavBar" data-v-64278d09 data-v-2f9a91a8><div class="wrapper" data-v-2f9a91a8><div class="container" data-v-2f9a91a8><div class="title" data-v-2f9a91a8><div class="VPNavBarTitle" data-v-2f9a91a8 data-v-db1abf29><a class="title" href="/blog/" data-v-db1abf29><!--[--><!--]--><!----><span data-v-db1abf29>Neo Blog</span><!--[--><!--]--></a></div></div><div class="content" data-v-2f9a91a8><div class="content-body" data-v-2f9a91a8><!--[--><!--]--><div class="VPNavBarSearch search" data-v-2f9a91a8><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-2f9a91a8 data-v-94e0de4d><span id="main-nav-aria-label" class="visually-hidden" data-v-94e0de4d> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/" tabindex="0" data-v-94e0de4d data-v-b04b12fe><!--[--><span data-v-b04b12fe>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blog/pages/sobre.html" tabindex="0" data-v-94e0de4d data-v-b04b12fe><!--[--><span data-v-b04b12fe>Sobre</span><!--]--></a><!--]--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="http://giseldo.github.io/cursos" target="_blank" rel="noreferrer" tabindex="0" data-v-94e0de4d data-v-b04b12fe><!--[--><span data-v-b04b12fe>Cursos</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-2f9a91a8 data-v-e6826308><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-e6826308 data-v-77e720fe data-v-b5a0f3c5><span class="check" data-v-b5a0f3c5><span class="icon" data-v-b5a0f3c5><!--[--><span class="vpi-sun sun" data-v-77e720fe></span><span class="vpi-moon moon" data-v-77e720fe></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-2f9a91a8 data-v-cb473b7f data-v-e0cde419><!--[--><a class="VPSocialLink no-icon" href="https://github.com/giseldo/blog" aria-label="github" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-github"></span></a><a class="VPSocialLink no-icon" href="https://twitter.com/giseldoneo" aria-label="twitter" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-twitter"></span></a><a class="VPSocialLink no-icon" href="https://instagram.com/neogiseldo" aria-label="instagram" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-instagram"></span></a><a class="VPSocialLink no-icon" href="https://youtube.com/giseldoneo" aria-label="youtube" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-youtube"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-2f9a91a8 data-v-c4883afd data-v-3980e32a><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-3980e32a><span class="vpi-more-horizontal icon" data-v-3980e32a></span></button><div class="menu" data-v-3980e32a><div class="VPMenu" data-v-3980e32a data-v-f8f1a359><!----><!--[--><!--[--><!----><div class="group" data-v-c4883afd><div class="item appearance" data-v-c4883afd><p class="label" data-v-c4883afd>Appearance</p><div class="appearance-action" data-v-c4883afd><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-c4883afd data-v-77e720fe data-v-b5a0f3c5><span class="check" data-v-b5a0f3c5><span class="icon" data-v-b5a0f3c5><!--[--><span class="vpi-sun sun" data-v-77e720fe></span><span class="vpi-moon moon" data-v-77e720fe></span><!--]--></span></span></button></div></div></div><div class="group" data-v-c4883afd><div class="item social-links" data-v-c4883afd><div class="VPSocialLinks social-links-list" data-v-c4883afd data-v-e0cde419><!--[--><a class="VPSocialLink no-icon" href="https://github.com/giseldo/blog" aria-label="github" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-github"></span></a><a class="VPSocialLink no-icon" href="https://twitter.com/giseldoneo" aria-label="twitter" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-twitter"></span></a><a class="VPSocialLink no-icon" href="https://instagram.com/neogiseldo" aria-label="instagram" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-instagram"></span></a><a class="VPSocialLink no-icon" href="https://youtube.com/giseldoneo" aria-label="youtube" target="_blank" rel="noopener" data-v-e0cde419 data-v-6b91c750><span class="vpi-social-youtube"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-2f9a91a8 data-v-6c970607><span class="container" data-v-6c970607><span class="top" data-v-6c970607></span><span class="middle" data-v-6c970607></span><span class="bottom" data-v-6c970607></span></span></button></div></div></div></div><div class="divider" data-v-2f9a91a8><div class="divider-line" data-v-2f9a91a8></div></div></div><!----></header><div class="VPLocalNav empty fixed" data-v-d8d3e66f data-v-f3371c70><div class="container" data-v-f3371c70><!----><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-f3371c70 data-v-7bf35b01><button data-v-7bf35b01>Início</button><!----></div></div></div><!----><div class="VPContent" id="VPContent" data-v-d8d3e66f data-v-6a411d75><div class="VPDoc" data-v-6a411d75 data-v-5e576dee><!--[--><!--]--><div class="container" data-v-5e576dee><!----><div class="content" data-v-5e576dee><div class="content-container" data-v-5e576dee><!--[--><!--[--><!--[--><div class="profile"><div class="profile-details">01/05/2024</div></div><div class="vp-doc"><h1>LLM Nemotron 70B</h1><p>Postagem explicando o LLM da Nvidia Nemotron</p><hr class="solid"><div class="profile"><img src="/blog/assets/giseldo.CWyzTLef.png"><div class="profile-details"><p>Giseldo Neo</p><p><a href="http://x.com/giseldoneo">@giseldoneo</a></p></div></div><hr class="solid"></div><!--]--><!--]--><!--]--><main class="main" data-v-5e576dee><div style="position:relative;" class="vp-doc _blog_posts_2024-05-01-llm-nemotron external-link-icon-enabled" data-v-5e576dee><div><p>Em julho de 2024, a Meta lançou um modelo de linguagem (LLM) open-source, o <em>Llama-3.1-70B</em>. Um pouco depois, em setembro a empresa NVIDIA lançou um derivado deste, o <em>Llama 3.1-Nemotron-51B-Instruct</em>. E em outubro lançou finalmente um modelo de 70b, o <em>Llama 3.1 nemotron-70b-instruct</em>.</p><p>O <em>nemotron-70b</em> performou melhor, em alguns testes comparativos, do que o GPT-4o. Nos testes, ele liderou em desempenho geral e também se destacou nas categorias chat (<em>chat score</em>) e raciocínio (<em>reasoning score</em>). Veja na <strong>Tabela 1</strong> os dados comparativos com mais detalhes.</p><!----><table tabindex="0"><thead><tr><th>Model</th><th style="text-align:right;">Overall Score</th><th style="text-align:right;">Chat Score</th><th style="text-align:right;">Reasoning Score</th></tr></thead><tbody><tr><td>Llama 3.1 Nemotron-70B</td><td style="text-align:right;">94.1</td><td style="text-align:right;">97.5</td><td style="text-align:right;">98.1</td></tr><tr><td>Skywork-Reward-Gemma-2-27B</td><td style="text-align:right;">93.8</td><td style="text-align:right;">95.8</td><td style="text-align:right;">96.1</td></tr><tr><td>TextEval-Llama3.1-70B</td><td style="text-align:right;">93.5</td><td style="text-align:right;">94.1</td><td style="text-align:right;">96.4</td></tr><tr><td>GPT-4o</td><td style="text-align:right;">86.7</td><td style="text-align:right;">96.1</td><td style="text-align:right;">86.6</td></tr></tbody></table><!----><h2 id="testes-de-uso" tabindex="-1">Testes de uso <a class="header-anchor" href="#testes-de-uso" aria-label="Permalink to &quot;Testes de uso&quot;">​</a></h2><p>O Nemontron pode ser testado em <a href="https://build.nvidia.com" target="_blank" rel="noreferrer">build.nvidia.com</a>, especificamente <a href="https://build.nvidia.com/nvidia/llama-3_1-nemotron-70b-instruct?snippet_tab=Node" target="_blank" rel="noreferrer">neste link</a>. A inscrição concede acesso a 100.000 chamadas de API gratuitas. Além disso, ele está disponível para baixar no <a href="https://huggingface.co/nvidia/Llama-3_1-Nemotron-51B-Instruct" target="_blank" rel="noreferrer">Hugging Face</a>. Porém, haja poder de processamento para uma consulta local a este modelo em uma PC de mesa.</p><p>Realizei algumas consultas no site da NVIDIA (<strong>Figura 1</strong>) e a velocidade da resposta deixou muito a desejar em relação a quantidade de tokens por minuto. Um versão do <a href="https://console.groq.com/playground" target="_blank" rel="noreferrer">Groq</a> disponível no Groq Cloud (<em>Figura 2</em>), que usa uma versão também customizada do Llama, o <em>llama3-groq-70b-8192-tool-use-preview</em>, é muito mais veloz do que a disponibilizada no site da NVIDIA. Provavelmente isto está relacionado mais ao hardware da Groq, que parece ser mais eficiente, independente do modelo. Cabe ressaltar que a versão da NVIDIA deu uma resposta bem mais completa que a versão do Groq, para o mesmo prompt.</p><p><strong>Figura 1</strong> - Demonstração do Nemotron 70B no site da NVidia</p><p>Fonte: O Autor (2024)</p><p><strong>Figura 2</strong> - Demonstração no Groq Cloud do modelo 70B tool use preview</p><p>Fonte: O Autor (2024)</p><h2 id="arquitetura" tabindex="-1">Arquitetura <a class="header-anchor" href="#arquitetura" aria-label="Permalink to &quot;Arquitetura&quot;">​</a></h2><p>Um LLM geralmente utiliza a arquitetura <em>transformer</em>, e no Nemotron não foi diferente. Esta arquitetura já é conhecida e permite que o modelo capture dependências de longo alcance no texto, tornando-o apto a compreender o contexto e a gerar respostas.</p><p>Outro recurso utilizado é o <em>Attention Multi-Head</em> que permite que o modelo se concentre em diferentes partes da entrada simultaneamente, aprimorando sua capacidade de compreender consultas complexas e produzir resultados diferenciados.</p><p>Por fim, foi implementado no modelo, a <em>normalização de camadas</em>. Ela ajuda a estabilizar o treinamento e a melhorar as taxas de convergência, resultando em um aprendizado mais rápido e eficiente. o modelo foi treinado em uma ampla gama de dados licenciados com a licença (CC-BY-4.0), que inclui livros, artigos e conteúdo da web. Ressaltando que o BY da licença exige que o crédito seja dado ao autor.</p><p>De acordo com a NVIDIA, o processo de treinamento do <em>Llama 3.1 Nemotron-70B</em> incluiu:</p><ul><li>aprendizagem supervisionada</li><li>aprendizagem por reforço de feedback humano.</li><li>Modelagem de recompensa: O modelo prevê a qualidade da resposta com base nas interações do usuário. Este mecanismo permite ajustar seus resultados de forma dinâmica, melhorando ao longo do tempo com base no feedback do mundo real.</li></ul><h2 id="codigo" tabindex="-1">Código <a class="header-anchor" href="#codigo" aria-label="Permalink to &quot;Código&quot;">​</a></h2><p>Em relação a código, a consulta ao modelo em python utiliza a mesma API do LLM da OpenAI (conforme pode ser visto no código abaixo), alterando somente a <em>base url</em>.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">client </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAI(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  base_url</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;https://integrate.api.nvidia.com/v1&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  api_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">completion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> client.chat.completions.create(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;nvidia/llama-3.1-nemotron-70b-instruct&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  messages</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;What is machine learning?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  temperature</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  top_p</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  max_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1024</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  stream</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> chunk </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> completion:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> chunk.choices[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].delta.content </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(chunk.choices[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].delta.content, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">end</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Curtiu? Deixei um comentário. Até o próximo post.</p><h3 id="referencias" tabindex="-1">Referências <a class="header-anchor" href="#referencias" aria-label="Permalink to &quot;Referências&quot;">​</a></h3><ul><li><a href="https://blog.getbind.co/2024/10/17/llama-3-1-nemotron-70b-is-it-better-for-coding-compared-to-gpt-4o-and-claude-3-5-sonnet/" target="_blank" rel="noreferrer">Bind AI Blog post</a></li><li><a href="https://creativecommons.org/share-your-work/cclicenses/" target="_blank" rel="noreferrer">CC-BY</a></li><li><a href="https://console.groq.com/" target="_blank" rel="noreferrer">GROQ</a></li><li><a href="https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b" target="_blank" rel="noreferrer">NVIDIA Blog post</a></li><li><a href="https://www.reddit.com/r/LocalLLaMA/comments/1fnp2kt/new_llama31nemotron51b_instruct_model_from_nvidia/" target="_blank" rel="noreferrer">Reddit post</a></li></ul></div></div></main><footer class="VPDocFooter" data-v-5e576dee data-v-7ae10264><!--[--><!--]--><div class="edit-info" data-v-7ae10264><div class="edit-link" data-v-7ae10264><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/giseldo/blog/edit/main/blog/posts/2024-05-01-llm-nemotron.md" target="_blank" rel="noreferrer" data-v-7ae10264><!--[--><span class="vpi-square-pen edit-link-icon" data-v-7ae10264></span> Edit this page<!--]--></a></div><div class="last-updated" data-v-7ae10264><p class="VPLastUpdated" data-v-7ae10264 data-v-08bf24d6>Atualizado em: <time datetime="2024-12-17T05:59:04.000Z" data-v-08bf24d6></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-7ae10264><span class="visually-hidden" id="doc-footer-aria-label" data-v-7ae10264>Pager</span><div class="pager" data-v-7ae10264><a class="VPLink link pager-link prev" href="/blog/posts/2024-04-01-redes-neurais-1.html" data-v-7ae10264><!--[--><span class="desc" data-v-7ae10264>Página anterior</span><span class="title" data-v-7ae10264>Redes Neurais (1#)</span><!--]--></a></div><div class="pager" data-v-7ae10264><a class="VPLink link pager-link next" href="/blog/posts/2024-11-19-codegpt.html" data-v-7ae10264><!--[--><span class="desc" data-v-7ae10264>Proxima página</span><span class="title" data-v-7ae10264>CodeGPT - Uma ferramenta de LLM para auxiliar o desenvolvimento</span><!--]--></a></div></nav></footer><!--[--><!--[--><!--[--><div class="custom-layout"> Se você está gostando da leitura, deixe um comentário ou curta esta postagem. Isso motiva os autores na criação de novos conteúdos. Caso queira receber semanalmente as últimas postagens por e-mail, assine nossa newsletter. </div><div class="custom-layout"><!--[--><!----><form class="newsletter"><!--[--><div class="newsletter__wrap"><div class="newsletter__title">Newsletter</div><div class="newsletter__content">Inscreva-se na nossa newsletter semanal. Sem spam.</div><input value="" class="newsletter__input" type="email" name="email" aria-label="Email" placeholder="Email" required autocapitalize="off" autocorrect="off" data-cy="email"><button type="submit" class="newsletter__button" data-cy="submit">Inscreva-se</button></div><!--]--></form><!--]--></div><!----><!----><div class="giscus"><script src="https://giscus.app/client.js" data-repo="giseldo/blog" data-repo-id="R_kgDONaUAxw" data-category="General" data-category-id="DIC_kwDONaUAx84ClDNp" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-lang="en" data-theme="light" data-loading="lazy" async></script></div><!--]--><!--]--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter" data-v-d8d3e66f data-v-bc8227f9><div class="container" data-v-bc8227f9><p class="message" data-v-bc8227f9>Todos os direitos reservados.</p><p class="copyright" data-v-bc8227f9>Copyright © 2024 Giseldo Neo</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"index.md\":\"CpTz1eUr\",\"pages_sobre.md\":\"Bf75n9sh\",\"posts_2024-01-01-streamlit.md\":\"Dd8vfmED\",\"posts_2024-02-01-am-1.md\":\"DDgH1ypt\",\"posts_2024-02-02-am-2-heuristicas.md\":\"jbFu0HXB\",\"posts_2024-03-01-regressao-linear-1.md\":\"BQqcXcGi\",\"posts_2024-04-01-redes-neurais-1.md\":\"DKHt4H8E\",\"posts_2024-05-01-llm-nemotron.md\":\"y6VXXL5R\",\"posts_2024-11-19-codegpt.md\":\"DpFUbb4S\",\"posts_2024-11-21-groq-vs-grok.md\":\"B58Nrnim\",\"posts_2024-11-23-ia-noticias.md\":\"CN6kjXeP\",\"posts_2024-12-08-avaliacao-por-pares.md\":\"DdRUYzU8\",\"posts_2024-12-12-redes-neurais-2.md\":\"e8ENfQ5Y\",\"posts_2024-12-13-fraudes-acadêmicas.md\":\"Rn21VGbm\",\"posts_2024-12-17-llm.md\":\"D5GgcvvZ\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"Neo Blog\",\"description\":\"Um blog com artigos sobre tecnologia, inteligência artificial e aprendizagem de máquina!\",\"base\":\"/blog/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"lastUpdated\":{\"text\":\"Atualizado em\",\"formatOptions\":{\"dateStyle\":\"full\",\"timeStyle\":\"medium\"}},\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Sobre\",\"link\":\"/pages/sobre\"},{\"text\":\"Cursos\",\"link\":\"http://giseldo.github.io/cursos\"}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/giseldo/blog\"},{\"icon\":\"twitter\",\"link\":\"https://twitter.com/giseldoneo\"},{\"icon\":\"instagram\",\"link\":\"https://instagram.com/neogiseldo\"},{\"icon\":\"youtube\",\"link\":\"https://youtube.com/giseldoneo\"}],\"editLink\":{\"pattern\":\"https://github.com/giseldo/blog/edit/main/blog/:path\"},\"search\":{\"provider\":\"local\"},\"externalLinkIcon\":true,\"aside\":true,\"lastUpdate\":true,\"docFooter\":{\"prev\":\"Página anterior\",\"next\":\"Proxima página\"},\"footer\":{\"message\":\"Todos os direitos reservados.\",\"copyright\":\"Copyright © 2024 Giseldo Neo\"},\"returnToTopLabel\":\"Início\",\"sidebarMenuLabel\":\"Menu\",\"sidebar\":[{\"text\":\"Pages\",\"items\":[{\"text\":\"Sobre\",\"link\":\"/pages/sobre\"}],\"collapsed\":false},{\"text\":\"Posts\",\"items\":[{\"text\":\"Streamlit (#1)\",\"link\":\"/posts/2024-01-01-streamlit\"},{\"text\":\"Aprendizagem de Máquina (#1)\",\"link\":\"/posts/2024-02-01-am-1\"},{\"text\":\"Aprendizagem de Máquina (#2) - Heurísticas\",\"link\":\"/posts/2024-02-02-am-2-heuristicas\"},{\"text\":\"Regressão Linear (1#)\",\"link\":\"/posts/2024-03-01-regressao-linear-1\"},{\"text\":\"Redes Neurais (1#)\",\"link\":\"/posts/2024-04-01-redes-neurais-1\"},{\"text\":\"LLM Nemotron 70B\",\"link\":\"/posts/2024-05-01-llm-nemotron\"},{\"text\":\"CodeGPT - Uma ferramenta de LLM para auxiliar o desenvolvimento\",\"link\":\"/posts/2024-11-19-codegpt\"},{\"text\":\"Groq vs Grok - Qual a diferença?\",\"link\":\"/posts/2024-11-21-groq-vs-grok\"},{\"text\":\"IA Notícias (23/11/2024)\",\"link\":\"/posts/2024-11-23-IA-noticias\"},{\"text\":\"Avaliação por pares\",\"link\":\"/posts/2024-12-08-avaliacao-por-pares\"},{\"text\":\"Redes Neurais (2#)\",\"link\":\"/posts/2024-12-12-redes-neurais-2\"},{\"text\":\"Fraudes Acadêmicas\",\"link\":\"/posts/2024-12-13-fraudes-acadêmicas\"},{\"text\":\"Acesso via API a Modelos LLM\",\"link\":\"/posts/2024-12-17-LLM\"}],\"collapsed\":false}]},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>